---
title: Rからおこなう係り受けを考慮したテキストの感情分析
author: paithiov909
date: "`r Sys.Date()`"
lastmod: '2020-07-11'
slug: sentiment-analysis
categories: []
tags:
  - NLP
description: 'CaboChaによる係り受け解析の結果を考慮したテキストの感情分析の例'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  tidy = "styler",
  collapse = TRUE,
  comment = "#>"
)

stopifnot(require(tidyverse))
TOKEN <- conifer::getAccessToken(Sys.getenv("PUB_URL"))
```

## はじめに

### 感情分析について

テキストの内容がポジティブなものかネガティブなものかを判定するあれです。

この記事の筆者は一応「感情」に関する研究がわりと得意とする領域だと思っている人間なので、そもそもテキストの「ネガポジ」を機械的に判定することにどれほどの意義があるのかといった点についてやや疑問に思う部分もあるのですが、こうした感情分析は自然言語処理におけるタスクとしてはけっこう注目されているものであるような気がします。

Rから日本語の感情分析を簡単に試すなら、[{conifer}](https://github.com/paithiov909/conifer)というオレオレパッケージを使って[COTOHA API](https://api.ce-cotoha.com/contents/index.html)を叩くことで実行することができます。

```{r}
client <- conifer::cotoha(TOKEN)
cotoha_res <- purrr::map(
  c(
    "俺の妹はこんなに可愛い",
    "俺の妹がこんなに可愛いわけがない",
    "俺の妹がこんなに可愛いわけがなくないですか",
    "俺の妹がこんなに可愛くないわけがない",
    "必ずしも可愛くなくないこともない",
    "必ずしも可愛くなくないこともないかもしれないな"
  ),
  ~ client$sentiment(.)
)

cotoha_res %>%
  purrr::map_dfr(~ tibble::tibble(
    emotion = .$sentiment,
    score = .$score,
    morphs = purrr::map_chr(.$emotional_phrase, ~ paste0(.$form, collapse = ""))
  )) %>%
  tibble::rowid_to_column() %>%
  dplyr::select(rowid, emotion, score, morphs) %>%
  knitr::kable()
```

ただ、この結果を見るとわかるように、こういうのは文意と正しく対応する結果が返ってくるケースばかりではありません。個人的にはむしろそれがそう解析されちゃうのかという感想のほうが大きくて、感情分析を精度よくこなすのはどうやらとても難しいタスクであるらしいことがうかがえます。

### 係り受けを考慮した感情分析

感情分析をやってみた系の情報はネットにもたくさん転がっていますが、たぶん大別すると極性辞書なんかを利用して素朴にネガポジ判定しているものと、感情がラベリングされた正解データを用いて自前で機械学習して分類問題として解いているものの2パターンがあります。

とりあえず手軽にやる分には極性辞書なりの既存のリソースを使えばよいと思います。ところが、それ系の記事を見るとだいたい決まって「こういうことするなら本当は係り受けとか文脈とか考慮しなきゃダメだよね」という文言が書かれています。たとえば、[R+RMeCabで感情分析](https://qiita.com/rmecab/items/b1a55a0e3a0a8637a461)には次のように書いてあります。

> ただし、たとえば「面白くない」という単語は「面白い」と「ない」に分解されるが、このフレーズ全体はマイナスな評価になる。ところが、単純にこのフレーズを評価すると「面白い」と「ない」のそれぞれ別々に完成評価（註：原文ママ）の値を与えてしまう。（中略）「面白くない」の評価として、それぞれの値を合算すると相殺されて、ほぼ 0 となってしまう。このように、正しくテキストを評価しようとすると文脈や係り受けを考慮することが必須である。

これはこの通りで誰もが一度は考えるあれなのですが、だから実際に係り受けを考慮した感情分析をやってみたという内容の記事はなぜかあまり見つかりません。なぜなんでしょうね。ともかく、ないならちょっと自分でやってみるかという感じで試しにやってみます。

## 極性辞書

研究用の日本語の極性辞書としては、東北大の乾・岡崎研究室が公開している[日本語評価極性辞書](http://www.cl.ecei.tohoku.ac.jp/index.php?Open%20Resources%2FJapanese%20Sentiment%20Polarity%20Dictionary)と東工大の高村教授が公開している[単語感情極性対応表](http://www.lr.pi.titech.ac.jp/~takamura/pndic_ja.html)があります。ただ、率直にいってクオリティとしてはどっちもどっちでそれほど実用的ではないらしいです。

ただ、他にはないのでとりあえず、ここでは単語感情極性対応表のほうを使います。この辞書の特徴として、単語感情極性対応表と比べて収録している語彙が圧倒的に多いのですが、振られている極性値がネガティブ寄りなのと、ときたまよくわからない極性値が振られている点があげられます。

読みこむ例です。

```{r}
pntable <- readr::read_delim(
  "http://www.lr.pi.titech.ac.jp/~takamura/pubs/pn_ja.dic",
  delim = ":",
  quote = "",
  col_names = FALSE,
  locale = locale(encoding = "Shift_JIS")
) %>%
  dplyr::filter(X3 != "助動詞") %>%
  dplyr::filter(abs(X4) > .8)

nrow(pntable)
```

都合上、語彙を少し削ります。また、見た目がまったく同じで読みや品詞が違う項目があると扱いづらいので表層形で`distinct`しておきます。

```{r}
pnt <- dplyr::sample_frac(pntable, 0.6) %>%
  dplyr::distinct(X1, .keep_all = TRUE)

nrow(pnt)
```

## 係り受け解析

[オレオレパッケージ](https://github.com/paithiov909/pipian)を使います。`pipian::CabochaTbl`の戻り値はR6クラスのオブジェクトで、`tbl2graph`というメソッドで一発で簡単に{igraph}のグラフオブジェクトに変換することができます。

```{r}
li <- purrr::map(
  c(
    "俺の妹はこんなに可愛い",
    "俺の妹がこんなに可愛いわけがない",
    "俺の妹がこんなに可愛いわけがなくないですか",
    "俺の妹がこんなに可愛くないわけがない",
    "必ずしも可愛くなくないこともない",
    "必ずしも可愛くなくないこともないかもしれないな"
  ),
  ~ pipian::CabochaTbl(.)
)

li[[3]]$tbl
```

ここでは関係ないですが、木構造のプロットもできます。

```{r}
li[[3]]$plot()
```

## 特性値を計算する方法

### 多重否定の考慮

この記事のフォーカスとして、先ほどの例でも試した「必ずしも可愛くなくないこともないかもしれないな」のような、しつこい多重否定をイイ感じに感情分析の結果に反映させたいというのがあります。そのために、文節ごとにその文節中の否定語の数を数えて、その数に応じて文節のネガポジの値を反転させます。

ただ、お試しなのでここは雑にやっています。日本語における否定語としては「ない・ず・ぬ」とその活用形に加えて「ありません」という表現における「ん」を網羅する必要がありますが、めんどうなので「ない」の活用形のみについて下手な正規表現を書いて済ませています。

### 文節の係り受けの考慮

これはこの記事でやっていることのポイントです。文ごとに否定表現があるかを判定し、否定表現があった場合にはその表現が係り先になるすべての文節（否定表現を含む文節それ自身は除く）についてその特性値を反転させるようにします。文節の特性値としては割り当てルールによって文節に割り当てられた、重み付けした極性値の総和をとります。

### 編集距離にもとづく極性値の重み付け

こういう辞書との照らし合わせみたいなことをするとき、テキストにあらわれる表現を辞書に収録されている表記にいかにして正規化していくかというのが地味ながらとても大事な作業だと思います。ただ、どうせ用言は活用したりするものだし、体言であっても漢字がかな文字に開かれていたりすると表記ゆれからは逃れられないので、ここでは極性値をもっとルーズに割り当ててしまうことを考えます。

具体的には、それぞれの文節について辞書の語彙項目との編集距離をとってみて、文字列として完全に一致していなくても見た目が似ていればその類似度に応じて重み付けした極性値を割り当ててしまうというアプローチを採ります。これをやってみるのに都合のよい編集距離として、Jaro-Winkler距離というものがあります。解説は以下の記事に譲りますが、ようするに0~1の範囲の値をとる編集距離で、値が0に近いほどまったく似ていない文字列であることをあらわし、文字列として完全に一致していると1になります。

- [【技術解説】似ている文字列がわかる！レーベンシュタイン距離とジャロ・ウィンクラー距離の計算方法とは](https://mieruca-ai.com/ai/levenshtein_jaro-winkler_distance/)

単語感情極性対応表で振られている極性値は-1~1の範囲の値をとるので、ふつうに乗算してしまっても問題ないです。ただし、この方法は感情分析する文節\*辞書にある語彙項目だけ編集距離を計算することになるため、単純に辞書とマッチングする場合に比べてめちゃくちゃ効率が悪いです。そのあたりは前処理をサボれるのとトレードオフかと。

## スニペット

RでJaro-Winkler距離を計算するには`stringdist::stringsim(method = "jw", p = 0.1)`を使います。

```{r}
tbl <- li %>%
  purrr::imap_dfr(function(res, idx){
    tbl <- res$tbl %>%
      dplyr::mutate(count = stringr::str_count(morphs, "(な)[かっ|く|けれ|い]+")) %>%
      dplyr::mutate(tag = dplyr::if_else(count %% 2 == 0, TRUE, FALSE))
    tbl <- tbl %>%
      dplyr::group_by(id) %>%
      dplyr::group_map(function(.x, .y){
        pnt %>%
          tidyr::expand_grid(.x) %>%
          dplyr::mutate(dist = stringdist::stringsim(X1, morphs, method = "jw", p = 0.1)) %>%
          dplyr::mutate(emotion = X4 * dist) %>%
          dplyr::select(id, X1, emotion)
      }, keep = TRUE) %>%
      purrr::map_dfr(~ .) %>%
      dplyr::left_join(tbl, by = "id") %>%
      tidyr::pivot_wider(
        id_cols = c(id, link, score, morphs, count, tag),
        names_from = X1,
        values_from = emotion,
        names_prefix = "sim_"
      )
    return(tibble::tibble(did = idx, tbl))
  })

head(tbl)
```

文中に否定表現があった場合、各文節についてその否定表現がその文節の係り先にあるかを判定するために、文の木構造においてその文節からターゲットとなる否定表現までの最短経路を求めています。グラフ理論はまったくのド素人なのですが、おそらく文の木構造というのはどこから入っても閉路のない有向グラフとかいうやつなので、その文節の係り先にある＝その文節からの最短経路があると考えることができるはずです。

```{r}
vpath <- tbl %>%
  dplyr::group_by(did) %>%
  dplyr::group_map(function(x, y) {
    graph <- li[[x$did[1]]]$tbl2graph()
    not <- x %>%
      dplyr::filter(count > 0) %>%
      dplyr::pull(id)
    path <- ifelse(
      length(not) == 0,
      list(),
      purrr::map(not, ~ igraph::shortest_paths(graph, from = x$id, to = ., mode = "out"))
    )
    return(path)
  }, keep = TRUE) %>%
  purrr::flatten() %>%
  purrr::map(~ purrr::pluck(., "vpath"))

vpath[[1]]
```

特性値を計算します。

```{r}
tbl <- purrr::imap_dfr(vpath, function(igraph_vs, idx){
  names <- attr(igraph_vs[[1]], "names")
  names <- names[1:length(names) - 1]
  tbl <- tbl %>%
    dplyr::filter(did == idx) %>%
    dplyr::mutate(tag = dplyr::if_else(id %in% names, !tag, tag)) %>%
    dplyr::mutate(emotion = dplyr::if_else(tag, 1, -1)) %>%
    dplyr::mutate(sumup = purrr::reduce(across(matches("sim_")), `+`)) %>%
    dplyr::mutate(result = sumup * emotion)
  return(tbl)
})

head(tbl)
```

整形して表示してみます。

```{r}
res <- tbl %>%
  dplyr::group_by(did) %>%
  dplyr::summarise_at("result", mean) %>%
  dplyr::ungroup() %>%
  dplyr::select(result) %>%
  tibble::rowid_to_column() %>%
  dplyr::right_join(
    tbl %>%
      dplyr::group_by(did) %>%
      dplyr::summarise_at("morphs", ~ paste0(., collapse = "")) %>%
      dplyr::ungroup() %>%
      dplyr::select(morphs) %>%
      tibble::rowid_to_column(),
    by = "rowid"
  )

knitr::kable(res)
```

COTOHA APIによる解析結果の再掲。

```{r}
cotoha_res %>%
  purrr::map_dfr(~ tibble::tibble(
    emotion = .$sentiment,
    score = .$score,
    morphs = purrr::map_chr(.$emotional_phrase, ~ paste0(.$form, collapse = ""))
  )) %>%
  tibble::rowid_to_column() %>%
  dplyr::select(rowid, emotion, score, morphs) %>%
  knitr::kable()
```

## むすび

### 所感

正直いって、私には「5. 必ずしも可愛くなくないこともない」や「6. 必ずしも可愛くなくないこともないかもしれないな」といった文が発話されるべき場面をうまく想定できないのでこれらに正解ラベルを用意できないのですが、多重否定をイイ感じに反映させたいというねらいに沿っていえば「4. 俺の妹がこんなに可愛くないわけがない」については「可愛くない」という表現をちゃんと反転できたように見えます。

### 参考になる記事

感情分析の流れやTipsなどについては以下の記事が参考になります。

- [【自然言語処理】感情分析の進め方＆ハマりやすいポイント](https://qiita.com/toshiyuki_tsutsui/items/604f92dbe6e20a18a17e)
- [感情分析に用いる極性辞書を自動生成する](https://qiita.com/g-k/items/1b7c765fa6520297ca7c)

また、テキストの特性値が何についてのものなのかに注目して感情解析をおこなう「観点感情分析」と呼ばれる自然言語処理タスクについては以下のスライドが詳しく扱っています。

- [感情の出どころを探る、一歩進んだ感情解析](https://www.slideshare.net/takahirokubo7792/ss-96203329)

### セッション情報

```{r}
sessioninfo::session_info()
```


